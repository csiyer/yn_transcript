{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial transcript yes/no analysis\n",
    "\n",
    "This code will read trial transcript PDFs and for each witness (and each questioner) quantify how many yes/no questions that witness is asked.\n",
    "\n",
    "Authors: Chris Iyer, Miles Zoltak\n",
    "Updated: 5/21/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input:\n",
    "- file path of folder containing transcript PDFs (currently, this should be run separately for each case/trial)\n",
    "\n",
    "Output:\n",
    "- writes a text file containing witness statistics, for each examiner, of # of yes/no questions and # total questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: there are some instances where the PDF reader just misses some lines, so this won't be 100% accurate. This code contains a couple shortcuts for guessing information that was lost in the PDF reading process.\n",
    "\n",
    "For example, look at `12RT.pdf` page 95 // loc 1721. Compare to `entire_transcript[1984825: 1984890]` or `lines[77314:77316]`--these are missing two lines between \"DIRECT EXAMINATION\" and \"A. POLICE OFFICER WITH THE...\"\n",
    "\n",
    "In this example, the examiner is not identified, and the question asked is not identified. This is rare. But in these rare cases, we will guess who the examiner is, and try to infer whether it was a yes/no question from the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install all dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install os\n",
    "!pip install re\n",
    "!pip install pypdf\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dir_path = \"example_transcripts\"\n",
    "files = [f for f in sorted(os.listdir(dir_path))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDFs to text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [01:06<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Read all the PDFs into a huge string, and then split into a big list of lines\n",
    "from pypdf import PdfReader\n",
    "from tqdm import tqdm\n",
    "\n",
    "entire_transcript = \"\"\n",
    "\n",
    "print('Processing PDFs to text...')\n",
    "for file in tqdm(files, total=len(files)):\n",
    "  reader = PdfReader(os.path.join(dir_path, file))\n",
    "  for page in reader.pages:\n",
    "    entire_transcript += page.extract_text() + '\\n'\n",
    "lines = entire_transcript.split('\\n')\n",
    "print('finished!\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process transcript into witness statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## HELPER FUNCTIONS ##############\n",
    "import re\n",
    "\n",
    "def clean_simple_line(line):\n",
    "    # removes punctuation/whitespace/numbers/non-letters\n",
    "    return re.sub(r'[^a-zA-Z\\s]', '', line).upper().strip() \n",
    "\n",
    "def line_is_witness_identifier(lines, i):\n",
    "    line = lines[i]\n",
    "    words = line.split(' ')\n",
    "    return len(words) < 6 and i < len(lines)-1 and ' as a witness' in lines[i+1].lower()\n",
    "\n",
    "def who_presents_this_witness(lines, witness_line_i): \n",
    "    for j in range(witness_line_i+1, witness_line_i+5): # scan the next few lines for keywords\n",
    "        if 'people' in lines[j].lower():\n",
    "            return 'people'\n",
    "        if 'defense' in lines[j].lower() or 'defendant' in lines[j].lower():\n",
    "            return 'defense'\n",
    "    return 'unknown'\n",
    "\n",
    "def line_is_examiner_identifier(line):\n",
    "    # each examination begins with a line like \"By Mr. Smith:\"  \n",
    "    return len(line.split(' ')) < 6 and line[0:2].lower() == 'by' and line.strip()[-1] == ':'\n",
    "\n",
    "def clean_examiner_name(examiner_line):\n",
    "    if '.' in examiner_line and ':' in examiner_line:\n",
    "        name_substr = examiner_line[examiner_line.find('.'):examiner_line.find(':')]\n",
    "        return clean_simple_line(name_substr)\n",
    "    \n",
    "    name_followed_by_colon = [w for w in examiner_line.split(' ') if ':' in w][0]\n",
    "    return clean_simple_line(name_followed_by_colon)\n",
    "\n",
    "def line_is_examination_identifier(lines, i):\n",
    "    line = lines[i]\n",
    "    return len(line.split()) < 4 and 'EXAMINATION' in line and ('CROSS' in line or 'DIRECT' in line) and i < len(lines)-1 and ( \n",
    "        line_is_examiner_identifier(lines[i+1]) or lines[i+1].startswith('Q.') or lines[i+1].startswith('A.')\n",
    "        )\n",
    "\n",
    "def is_answer(line):\n",
    "    return line.strip().startswith('A. ') # or line.strip().startswith('THE WITNESS:')\n",
    "\n",
    "############################## MILES HELP WITH THESE ######################################\n",
    "\n",
    "def is_question(string):\n",
    "    # question classifier to see if utterance is a question (to rule out lines like \"Q: good morning.\")\n",
    "    # ideally, this will also rule out somewhat random strings (e.g., \"DIRECT EXAMINATION       By MR. ARNOLD\")\n",
    "    #   this ^ will be helpful for when a question is missing from the pdf reader\n",
    "    pass\n",
    "\n",
    "def is_yes_no(question):\n",
    "    # returns true if the question is a yes/no question \n",
    "    pass\n",
    "\n",
    "############################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default examiner default guesses:  {'people': 'ARNOLD', 'defense': 'JAFFE'} \n",
      "If these look incorrect, please stop and revise.\n"
     ]
    }
   ],
   "source": [
    "# there are some instances where the 'examiner identification' line isn't read properly by the pdf reader\n",
    "# for these, we need a default guess for who the examiner is.\n",
    "# so, we'll find the first direct examination for each side (people/defense) and save who the examiner is -- this is a good guess\n",
    "\n",
    "DEFAULT_EXAMINER_KEY = {'people': '', 'defense': ''}\n",
    "found = {'people': False, 'defense': False}\n",
    "for i in range(len(lines)):\n",
    "    if line_is_witness_identifier(lines, i):\n",
    "        side = who_presents_this_witness(lines, i)\n",
    "        if side != 'unknown' and not found[side]:\n",
    "            # search the next 200 lines for a direct exam, if found one then get the examiner ID\n",
    "            direct_exam_found = True\n",
    "            for j,line in enumerate(lines[i:i+200]):\n",
    "                if line_is_examination_identifier(lines, i+j) and 'DIRECT' in line:\n",
    "                    direct_exam_found = True\n",
    "                if direct_exam_found and line_is_examiner_identifier(line):\n",
    "                    DEFAULT_EXAMINER_KEY[side] = clean_examiner_name(line)\n",
    "                    found[side] = True\n",
    "                    break\n",
    "    if found['people'] and found['defense']: \n",
    "        break\n",
    "    \n",
    "print('Default examiner default guesses: ', DEFAULT_EXAMINER_KEY, '\\nIf these look incorrect, please stop and revise.')\n",
    "\n",
    "\n",
    "def guess_examiner(witness_side, current_examination):\n",
    "    print('Examiner not found, guessing from previous records (this should be rare).')\n",
    "    if 'DIRECT' in current_examination.upper():\n",
    "        return DEFAULT_EXAMINER_KEY[witness_side]\n",
    "    elif 'CROSS' in current_examination.upper():\n",
    "        other_side = [i for i in DEFAULT_EXAMINER_KEY.keys() if i != witness_side][0]\n",
    "        return DEFAULT_EXAMINER_KEY[other_side]\n",
    "    return 'error: unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examiner not found, guessing from previous records (this should be rare).\n"
     ]
    }
   ],
   "source": [
    "# loop through lines and compile statistics\n",
    "name_to_stats = {}\n",
    "\n",
    "current_witness = ''\n",
    "current_witness_side = ''\n",
    "current_examination = ''\n",
    "current_examiner = ''\n",
    "active_utterance = ''\n",
    "\n",
    "for i,line in enumerate(lines):\n",
    "    \n",
    "    if line_is_witness_identifier(lines, i):\n",
    "        current_witness = clean_simple_line(line)\n",
    "        current_witness_side = who_presents_this_witness(lines, i)\n",
    "        if current_witness not in name_to_stats.keys():\n",
    "            name_to_stats[current_witness] = {}\n",
    "        active_utterance = ''\n",
    "\n",
    "    if line_is_examination_identifier(lines, i):\n",
    "        current_examiner = ''\n",
    "        current_examination = clean_simple_line(line)\n",
    "        active_utterance = ''\n",
    "    \n",
    "    if line_is_examiner_identifier(line):\n",
    "        current_examiner = clean_examiner_name(line)\n",
    "        if current_examiner not in name_to_stats[current_witness].keys():\n",
    "            name_to_stats[current_witness][current_examiner] = {'total_questions': 0, 'yes_no_questions': 0}\n",
    "        active_utterance = ''\n",
    "\n",
    "    if line.startswith('Q.') or line.startswith(current_examiner+':'):\n",
    "        active_utterance = '' # reset to current line\n",
    "    active_utterance += line # add current line to active question \n",
    "\n",
    "    if is_answer(line):\n",
    "        if current_examiner == '': # error in pdf reading: no examiner info \n",
    "            current_examiner = guess_examiner(current_witness_side, current_examination)\n",
    "\n",
    "        if is_question(active_utterance): # to rule out things like \"Q. Good morning.\"\n",
    "            name_to_stats[current_witness][current_examiner]['total_questions'] += 1\n",
    "            if is_yes_no(active_utterance):\n",
    "                name_to_stats[current_witness][current_examiner]['yes_no_questions'] += 1\n",
    "    \n",
    "        active_utterance = ''\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_text = 'Witness Yes/No Question Statistics \\n\\n'\n",
    "\n",
    "for name,values in name_to_stats.items():\n",
    "    output_text += f'Witness: {name}\\n'\n",
    "    for examiner, stats in values.items():\n",
    "        output_text += f'\\tExaminer: {examiner}\\n'\n",
    "        output_text += f'\\t\\t Yes/no questions: {stats[\"yes_no_questions\"]}\\n'\n",
    "        output_text += f'\\t\\t Total questions: {stats[\"total_questions\"]}\\n'\n",
    "\n",
    "        try:\n",
    "            percentage = round(stats['yes_no_questions'] / stats['total_questions'] * 100, 2)\n",
    "        except:\n",
    "             percentage = 'error: no questions'\n",
    "        output_text += f'\\t\\t Yes/no percentage: {percentage}%\\n'\n",
    "    output_text += '\\n'\n",
    "\n",
    "with open('yn_transcript_output.txt', 'w') as file:\n",
    "    file.write(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random old miles code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"shahrukhx01/question-vs-statement-classifier\")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"shahrukhx01/question-vs-statement-classifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"shahrukhx01/question-vs-statement-classifier\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"shahrukhx01/question-vs-statement-classifier\")\n",
    "\n",
    "def classify_text(text):\n",
    "    # Tokenize the text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "    # Perform inference\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "    # Apply softmax to logits\n",
    "    probabilities = F.softmax(outputs.logits, dim=1)\n",
    "\n",
    "    # Get probability of being a question\n",
    "    probability_question = probabilities[0][1].item()  # Probability for 'question' class\n",
    "\n",
    "    return probability_question"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
