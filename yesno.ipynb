{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial transcript yes/no analysis\n",
    "\n",
    "This code will read trial transcript PDFs and for each witness (and each questioner) quantify how many yes/no questions that witness is asked.\n",
    "\n",
    "Authors: Chris Iyer, Miles Zoltak\n",
    "Updated: 5/21/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input:\n",
    "- file path of folder containing transcript PDFs (currently, this should be run separately for each case/trial)\n",
    "\n",
    "Output:\n",
    "- writes a text file containing witness statistics, for each examiner, of # of yes/no questions and # total questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: there are some instances where the PDF reader just misses some lines, so this won't be 100% accurate. This code contains a couple shortcuts for guessing information that was lost in the PDF reading process.\n",
    "\n",
    "For example, look at `12RT.pdf` page 95 // loc 1721. Compare to `entire_transcript[1984825: 1984890]` or `lines[77314:77316]`--these are missing two lines between \"DIRECT EXAMINATION\" and \"A. POLICE OFFICER WITH THE...\"\n",
    "\n",
    "In this example, the examiner is not identified, and the question asked is not identified. This is rare. But in these rare cases, we will guess who the examiner is, and try to infer whether it was a yes/no question from the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pypdf\n",
    "# %pip install tqdm\n",
    "# %pip install transformers\n",
    "# %pip install torch\n",
    "# %pip install openai\n",
    "\n",
    "import os, re\n",
    "from pypdf import PdfReader\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"example_transcripts\"\n",
    "files = [f for f in sorted(os.listdir(dir_path))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all the PDFs into a huge string, and then split into a big list of lines\n",
    "entire_transcript = \"\"\n",
    "print('Processing PDFs to text...')\n",
    "for file in tqdm(files, total=len(files)):\n",
    "  reader = PdfReader(os.path.join(dir_path, file))\n",
    "  for page in reader.pages:\n",
    "    entire_transcript += page.extract_text() + '\\n'\n",
    "print('finished!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate into lines, and filter out the ones that are just line numbers, e.g. \"24 \"\n",
    "lines = entire_transcript.split('\\n')\n",
    "lines = [line for line in lines if not re.match(r'^[\\d\\s]*$', line)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process transcript into witness statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "def delete_numbers_whitespace(text):\n",
    "    return re.sub(r'[\\d\\t\\n]', '', text).strip()\n",
    "\n",
    "def clean_simple_line(line):\n",
    "    # removes punctuation/numbers/non-letters\n",
    "    return re.sub(r'[^a-zA-Z\\s]', '', line).upper().strip() \n",
    "\n",
    "def line_is_witness_identifier(lines, i):\n",
    "    line = clean_simple_line(lines[i])\n",
    "    words = line.split(' ')\n",
    "    return len(words) < 6 and i < len(lines)-1 and ' as a witness' in lines[i+1].lower()\n",
    "\n",
    "def who_presents_this_witness(lines, witness_line_i): \n",
    "    for j in range(witness_line_i+1, witness_line_i+5): # scan the next few lines for keywords\n",
    "        if 'people' in lines[j].lower():\n",
    "            return 'people'\n",
    "        if 'defense' in lines[j].lower() or 'defendant' in lines[j].lower():\n",
    "            return 'defense'\n",
    "    return 'unknown'\n",
    "\n",
    "def line_is_examiner_identifier(line):\n",
    "    # each examination begins with a line like \"By Mr. Smith:\"  \n",
    "    line = re.sub(r'\\d+', '', line).strip() # eliminate leading numbers + whitespace. we don't want clean_simple_line because we want to keep colon if there is one\n",
    "    return len(line.split(' ')) < 6 and line[0:2].lower() == 'by' and line.strip()[-1] == ':'\n",
    "\n",
    "def clean_examiner_name(examiner_line):\n",
    "    if '.' in examiner_line and ':' in examiner_line:\n",
    "        name_substr = examiner_line[examiner_line.find('.'):examiner_line.find(':')]\n",
    "        return clean_simple_line(name_substr)\n",
    "    \n",
    "    name_followed_by_colon = [w for w in examiner_line.split(' ') if ':' in w][0]\n",
    "    return clean_simple_line(name_followed_by_colon)\n",
    "\n",
    "def line_is_examination_identifier(lines, i):\n",
    "    line = clean_simple_line(lines[i])\n",
    "    return len(line.split()) < 4 and 'EXAMINATION' in line and ('CROSS' in line or 'DIRECT' in line) and i < len(lines)-1 and ( \n",
    "        line_is_examiner_identifier(lines[i+1]) or lines[i+1].startswith('Q.') or lines[i+1].startswith('A.')\n",
    "        )\n",
    "\n",
    "def is_answer(line):\n",
    "    return line.strip().startswith('A. ') # or line.strip().startswith('THE WITNESS:')\n",
    "\n",
    "def starts_question(text, current_examiner):\n",
    "    return any(item in text for item in ['Q. ', 'Q . ', 'Q• ', 'Q • ', current_examiner+':'])# and '?' in text\n",
    "\n",
    "def guess_previous_question(lines, i):\n",
    "    # if the previous question was not read in properly with 'Q.', then we want to parse what the question was when we hit an answer\n",
    "    possible_question = lines[i-1]\n",
    "    for prevline in reversed(lines[i-11:i-2]): # check previous 10 lines for question, stop when we hit punctuation\n",
    "        if prevline.strip().endswith(('.','!','?')) or any(item in prevline for item in ['A. ', 'A . ']):\n",
    "            break\n",
    "        possible_question = prevline + possible_question\n",
    "    return delete_numbers_whitespace(possible_question) \n",
    "\n",
    "def is_yes_no_answer(lines,i,current_examiner):\n",
    "    # querying chatGPT for yes/no questions is very time consuming, so we only want to do it if we cannot tell from the answer itself\n",
    "    answer = lines[i]\n",
    "    for nextline in lines[i+1:i+10]: # check next lines and add continuance of answer if necessary\n",
    "        if nextline.strip().endswith(('.','!','?')) or is_answer(nextline) or starts_question(nextline, current_examiner):\n",
    "            break\n",
    "        answer += nextline\n",
    "\n",
    "    answer_split = re.sub(r'[^A-Za-z ]', '', answer).upper().strip().split(' ')\n",
    "    if any(item in answer_split for item in ['YES', 'YEAH', 'NO', 'NOPE']):\n",
    "        if len(answer_split) < 8:\n",
    "            return 'yes'\n",
    "        return 'maybe'\n",
    "    return 'no'\n",
    "\n",
    "def is_yes_no(question):\n",
    "    # returns true if the question is a yes/no question. queries GPT to do so!\n",
    "    with open('key.txt', 'r') as f:\n",
    "        KEY = f.read()\n",
    "    client = OpenAI(api_key=KEY)\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert at identifying yes/no questions, and at analyzing courtroom transcripts.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Is the following question a yes or no question? Respond with 'yes' or 'no':\\n\\nQuestion: {question}\"}\n",
    "        ]\n",
    "    )\n",
    "    return 'yes' == completion.choices[0].message.content.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default examiner default guesses:  {'people': 'ARNOLD', 'defense': 'JAFFE'} \n",
      "If these look incorrect, please stop and revise.\n"
     ]
    }
   ],
   "source": [
    "# there are some instances where the 'examiner identification' line isn't read properly by the pdf reader\n",
    "# for these, we need a default guess for who the examiner is.\n",
    "# so, we'll find the first direct examination for each side (people/defense) and save who the examiner is -- this is a good guess\n",
    "\n",
    "DEFAULT_EXAMINER_KEY = {'people': '', 'defense': ''}\n",
    "found = {'people': False, 'defense': False}\n",
    "for i in range(len(lines)):\n",
    "    if line_is_witness_identifier(lines, i):\n",
    "        side = who_presents_this_witness(lines, i)\n",
    "        if side != 'unknown' and not found[side]:\n",
    "            # search the next 200 lines for a direct exam, if found one then get the examiner ID\n",
    "            direct_exam_found = True\n",
    "            for j,line in enumerate(lines[i:i+200]):\n",
    "                if line_is_examination_identifier(lines, i+j) and 'DIRECT' in line:\n",
    "                    direct_exam_found = True\n",
    "                if direct_exam_found and line_is_examiner_identifier(line):\n",
    "                    DEFAULT_EXAMINER_KEY[side] = clean_examiner_name(line)\n",
    "                    found[side] = True\n",
    "                    break\n",
    "    if found['people'] and found['defense']: \n",
    "        break\n",
    "    \n",
    "print('Default examiner default guesses: ', DEFAULT_EXAMINER_KEY, '\\nIf these look incorrect, please stop and revise.')\n",
    "\n",
    "def guess_examiner(witness_side, current_examination):\n",
    "    print('Examiner not found, guessing from previous records (this message should be rare).')\n",
    "    if 'DIRECT' in current_examination.upper():\n",
    "        return DEFAULT_EXAMINER_KEY[witness_side]\n",
    "    elif 'CROSS' in current_examination.upper():\n",
    "        other_side = [i for i in DEFAULT_EXAMINER_KEY.keys() if i != witness_side][0]\n",
    "        return DEFAULT_EXAMINER_KEY[other_side]\n",
    "    return 'error: unknown examiner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "Examiner not found, guessing from previous records (this message should be rare).\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "Finished transcript. Total number of lines needing GPT query: 329 out of 140348 (0.0)\n"
     ]
    }
   ],
   "source": [
    "#### LOOP THROUGH AND ANALYZE TRANSCRIPT\n",
    "name_to_stats = {}\n",
    "\n",
    "current_witness = ''\n",
    "current_witness_side = ''\n",
    "current_examination = ''\n",
    "current_examiner = ''\n",
    "active_question = ''\n",
    "\n",
    "idxs = []\n",
    "\n",
    "for i,line in enumerate(lines):\n",
    "    if line_is_witness_identifier(lines, i):\n",
    "        current_witness = clean_simple_line(line)\n",
    "        current_witness_side = who_presents_this_witness(lines, i)\n",
    "        if current_witness not in name_to_stats.keys():\n",
    "            name_to_stats[current_witness] = {}\n",
    "        active_question = '' # just in case we get carried away\n",
    "\n",
    "    elif line_is_examination_identifier(lines, i):\n",
    "        current_examiner = ''\n",
    "        current_examination = clean_simple_line(line)\n",
    "        active_question = ''\n",
    "        if current_witness == 'DESHAUNNA CODY THOMAS':\n",
    "            idxs.append(i)\n",
    "\n",
    "    elif line_is_examiner_identifier(line):\n",
    "        current_examiner = clean_examiner_name(line)\n",
    "        active_question = ''\n",
    "\n",
    "    # when we hit an answer, I want the active_question to be everything since the last question\n",
    "    elif starts_question(line, current_examiner):\n",
    "        active_question = line # start adding to active_question\n",
    "\n",
    "    elif is_answer(line):\n",
    "        if current_examiner == '': # error in pdf reading: no examiner info \n",
    "            current_examiner = guess_examiner(current_witness_side, current_examination)\n",
    "\n",
    "        if active_question == '':\n",
    "            active_question = guess_previous_question(lines, i)\n",
    "\n",
    "        if '?' in active_question: # to rule out things like \"Q. Good morning.\"\n",
    "            if current_examiner not in name_to_stats[current_witness].keys():\n",
    "                name_to_stats[current_witness][current_examiner] = {'total_questions': 0, 'yes_no_questions': 0}\n",
    "\n",
    "            name_to_stats[current_witness][current_examiner]['total_questions'] += 1\n",
    "\n",
    "            yes_no = is_yes_no_answer(lines, i, current_examiner)\n",
    "            if yes_no == 'yes':\n",
    "                name_to_stats[current_witness][current_examiner]['yes_no_questions'] += 1\n",
    "\n",
    "            elif yes_no == 'maybe' and is_yes_no(active_question): # query gpt only if we have to\n",
    "                idxs.append(i)\n",
    "                name_to_stats[current_witness][current_examiner]['yes_no_questions'] += 1\n",
    "\n",
    "        active_question = '' # reset\n",
    "\n",
    "    elif active_question:\n",
    "        active_question += line # if we started a question, add this line. resets at every answer or special identifying line\n",
    "\n",
    "    if i % 10000 == 0:\n",
    "        print(i)\n",
    "print(f'Finished transcript. Total number of lines needing GPT query: {len(idxs)} out of {len(lines)} ({round(len(idxs)/len(lines), 2)})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_id(lines):\n",
    "    for l in lines[0:30]:\n",
    "        if 'NO. ' in l: # case number\n",
    "            return 'case-' + l.split('NO. ')[1].strip()\n",
    "    return datetime.now().strftime('date-%Y-%m-%d_%H-%M')\n",
    "\n",
    "\n",
    "output_text = 'Witness Yes/No Question Statistics \\n\\n'\n",
    "\n",
    "for name,values in name_to_stats.items():\n",
    "    output_text += f'Witness: {name}\\n'\n",
    "    for examiner, stats in values.items():\n",
    "        output_text += f'\\tExaminer: {examiner}\\n'\n",
    "        output_text += f'\\t\\t Yes/no questions: {stats[\"yes_no_questions\"]}\\n'\n",
    "        output_text += f'\\t\\t Total questions: {stats[\"total_questions\"]}\\n'\n",
    "\n",
    "        try:\n",
    "            percentage = round(stats['yes_no_questions'] / stats['total_questions'] * 100, 2)\n",
    "        except:\n",
    "             percentage = 'error: no questions'\n",
    "        output_text += f'\\t\\t Yes/no percentage: {percentage}%\\n'\n",
    "    output_text += '\\n'\n",
    "\n",
    "with open(f'yn_transcript_output_{get_unique_id(lines)}.txt', 'w') as file: # CHANGE FILENAME TO UNIQUE ID\n",
    "    file.write(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506 1244\n"
     ]
    }
   ],
   "source": [
    "# THERE ARE MANY PROBLEMS\n",
    "# lines that are either questions or answers, that don't start with Q. or A. when the pdf is read by this software :(\n",
    "# this gets all the indices of those -- fix later\n",
    "\n",
    "current = ''\n",
    "i1 = []\n",
    "i2 = []\n",
    "for i,line in enumerate(lines):\n",
    "    if 'THE COURT' in line or 'OBJECTION' in line.upper():\n",
    "        current = ''\n",
    "    if 'Q. ' in line[0:10]:\n",
    "        if current=='question':\n",
    "            i1.append(i)\n",
    "        current = 'question'\n",
    "    if 'A. ' in line[0:10]:\n",
    "        if current=='answer':\n",
    "            i2.append(i)\n",
    "        current = 'answer'\n",
    "print(len(i1), len(i2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
