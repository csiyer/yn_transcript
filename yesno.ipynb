{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial transcript yes/no analysis\n",
    "\n",
    "This code will read trial transcript PDFs and for each witness (and each questioner) quantify how many yes/no questions that witness is asked.\n",
    "\n",
    "Authors: Chris Iyer, Miles Zoltak\n",
    "Updated: 5/21/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input:\n",
    "- file path of folder containing transcript PDFs (currently, this should be run separately for each case/trial)\n",
    "\n",
    "Output:\n",
    "- writes a text file containing witness statistics, for each examiner, of # of yes/no questions and # total questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: there are some instances where the PDF reader just misses some lines, so this won't be 100% accurate. This code contains a couple shortcuts for guessing information that was lost in the PDF reading process.\n",
    "\n",
    "For example, look at `12RT.pdf` page 95 // loc 1721. Compare to `entire_transcript[1984825: 1984890]` or `lines[77314:77316]`--these are missing two lines between \"DIRECT EXAMINATION\" and \"A. POLICE OFFICER WITH THE...\"\n",
    "\n",
    "In this example, the examiner is not identified, and the question asked is not identified. This is rare. But in these rare cases, we will guess who the examiner is, and try to infer whether it was a yes/no question from the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install all dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (4.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tqdm in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: transformers in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (4.41.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from transformers) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from transformers) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: openai in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (1.30.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from openai) (2.7.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\ciyer\\miniconda3\\envs\\hcrc\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pypdf\n",
    "%pip install tqdm\n",
    "\n",
    "%pip install transformers\n",
    "%pip install torch\n",
    "%pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dir_path = \"example_transcripts\"\n",
    "files = [f for f in sorted(os.listdir(dir_path))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDFs to text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:46<00:00,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Read all the PDFs into a huge string, and then split into a big list of lines\n",
    "from pypdf import PdfReader\n",
    "from tqdm import tqdm\n",
    "\n",
    "entire_transcript = \"\"\n",
    "\n",
    "print('Processing PDFs to text...')\n",
    "for file in tqdm(files, total=len(files)):\n",
    "  reader = PdfReader(os.path.join(dir_path, file))\n",
    "  for page in reader.pages:\n",
    "    entire_transcript += page.extract_text() + '\\n'\n",
    "lines = entire_transcript.split('\\n')\n",
    "print('finished!\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process transcript into witness statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## HELPER FUNCTIONS ##############\n",
    "import re\n",
    "\n",
    "def clean_simple_line(line):\n",
    "    # removes punctuation/whitespace/numbers/non-letters\n",
    "    return re.sub(r'[^a-zA-Z\\s]', '', line).upper().strip() \n",
    "\n",
    "def line_is_witness_identifier(lines, i):\n",
    "    line = clean_simple_line(lines[i])\n",
    "    words = line.split(' ')\n",
    "    return len(words) < 6 and i < len(lines)-1 and ' as a witness' in lines[i+1].lower()\n",
    "\n",
    "def who_presents_this_witness(lines, witness_line_i): \n",
    "    for j in range(witness_line_i+1, witness_line_i+5): # scan the next few lines for keywords\n",
    "        if 'people' in lines[j].lower():\n",
    "            return 'people'\n",
    "        if 'defense' in lines[j].lower() or 'defendant' in lines[j].lower():\n",
    "            return 'defense'\n",
    "    return 'unknown'\n",
    "\n",
    "def line_is_examiner_identifier(line):\n",
    "    # each examination begins with a line like \"By Mr. Smith:\"  \n",
    "    line = re.sub(r'\\d+', '', line).strip() # eliminate leading numbers + whitespace. we don't want clean_simple_line because we want to keep colon if there is one\n",
    "    return len(line.split(' ')) < 6 and line[0:2].lower() == 'by' and line.strip()[-1] == ':'\n",
    "\n",
    "def clean_examiner_name(examiner_line):\n",
    "    if '.' in examiner_line and ':' in examiner_line:\n",
    "        name_substr = examiner_line[examiner_line.find('.'):examiner_line.find(':')]\n",
    "        return clean_simple_line(name_substr)\n",
    "    \n",
    "    name_followed_by_colon = [w for w in examiner_line.split(' ') if ':' in w][0]\n",
    "    return clean_simple_line(name_followed_by_colon)\n",
    "\n",
    "def line_is_examination_identifier(lines, i):\n",
    "    line = clean_simple_line(lines[i])\n",
    "    return len(line.split()) < 4 and 'EXAMINATION' in line and ('CROSS' in line or 'DIRECT' in line) and i < len(lines)-1 and ( \n",
    "        line_is_examiner_identifier(lines[i+1]) or lines[i+1].startswith('Q.') or lines[i+1].startswith('A.')\n",
    "        )\n",
    "\n",
    "def is_answer(line):\n",
    "    return line.strip().startswith('A. ') # or line.strip().startswith('THE WITNESS:')\n",
    "\n",
    "def starts_question(text, current_examiner):\n",
    "    return 'Q. ' in text or current_examiner+':' in text # and '?' in text\n",
    "\n",
    "from openai import OpenAI\n",
    "def is_yes_no(question):\n",
    "    # returns true if the question is a yes/no question. queries GPT to do so!\n",
    "    with open('key.txt', 'r') as f:\n",
    "        KEY = f.read()\n",
    "    client = OpenAI(api_key=KEY)\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert at identifying yes/no questions, and at analyzing courtroom transcripts.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Is the following question a yes or no question? Respond with 'yes' or 'no':\\n\\nQuestion: {question}\"}\n",
    "        ]\n",
    "    )\n",
    "    return 'yes' == completion.choices[0].message.content.strip().lower()\n",
    "\n",
    "\n",
    "\n",
    "######################### NOT CURRENTLY USING ###################################################################\n",
    "\n",
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "def is_question_backup(text):\n",
    "    # uses a more sophisticated pre-trained model to identify questions\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"shahrukhx01/question-vs-statement-classifier\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"shahrukhx01/question-vs-statement-classifier\")\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    probabilities = softmax(outputs.logits, dim=1)\n",
    "    return probabilities[0][1].item() > 0.5  # Probability for 'question' class is above 50%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default examiner default guesses:  {'people': 'ARNOLD', 'defense': 'JAFFE'} \n",
      "If these look incorrect, please stop and revise.\n"
     ]
    }
   ],
   "source": [
    "# there are some instances where the 'examiner identification' line isn't read properly by the pdf reader\n",
    "# for these, we need a default guess for who the examiner is.\n",
    "# so, we'll find the first direct examination for each side (people/defense) and save who the examiner is -- this is a good guess\n",
    "\n",
    "DEFAULT_EXAMINER_KEY = {'people': '', 'defense': ''}\n",
    "found = {'people': False, 'defense': False}\n",
    "for i in range(len(lines)):\n",
    "    if line_is_witness_identifier(lines, i):\n",
    "        side = who_presents_this_witness(lines, i)\n",
    "        if side != 'unknown' and not found[side]:\n",
    "            # search the next 200 lines for a direct exam, if found one then get the examiner ID\n",
    "            direct_exam_found = True\n",
    "            for j,line in enumerate(lines[i:i+200]):\n",
    "                if line_is_examination_identifier(lines, i+j) and 'DIRECT' in line:\n",
    "                    direct_exam_found = True\n",
    "                if direct_exam_found and line_is_examiner_identifier(line):\n",
    "                    DEFAULT_EXAMINER_KEY[side] = clean_examiner_name(line)\n",
    "                    found[side] = True\n",
    "                    break\n",
    "    if found['people'] and found['defense']: \n",
    "        break\n",
    "    \n",
    "print('Default examiner default guesses: ', DEFAULT_EXAMINER_KEY, '\\nIf these look incorrect, please stop and revise.')\n",
    "\n",
    "\n",
    "def guess_examiner(witness_side, current_examination):\n",
    "    print('Examiner not found, guessing from previous records (this message should be rare).')\n",
    "    if 'DIRECT' in current_examination.upper():\n",
    "        return DEFAULT_EXAMINER_KEY[witness_side]\n",
    "    elif 'CROSS' in current_examination.upper():\n",
    "        other_side = [i for i in DEFAULT_EXAMINER_KEY.keys() if i != witness_side][0]\n",
    "        return DEFAULT_EXAMINER_KEY[other_side]\n",
    "    return 'error: unknown examiner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through lines and compile statisticsb\n",
    "name_to_stats = {}\n",
    "\n",
    "current_witness = ''\n",
    "current_witness_side = ''\n",
    "current_examination = ''\n",
    "current_examiner = ''\n",
    "\n",
    "active_question = ''\n",
    "\n",
    "idxs = []\n",
    "\n",
    "for i,line in enumerate(lines):\n",
    "    if line_is_witness_identifier(lines, i):\n",
    "        current_witness = clean_simple_line(line)\n",
    "        current_witness_side = who_presents_this_witness(lines, i)\n",
    "        if current_witness not in name_to_stats.keys():\n",
    "            name_to_stats[current_witness] = {}\n",
    "        active_question = '' # just in case we get carried away\n",
    "\n",
    "    elif line_is_examination_identifier(lines, i):\n",
    "        current_examiner = ''\n",
    "        current_examination = clean_simple_line(line)\n",
    "        active_question = ''\n",
    "        if current_witness == 'DESHAUNNA CODY THOMAS':\n",
    "            idxs.append(i)\n",
    "\n",
    "    elif line_is_examiner_identifier(line):\n",
    "        current_examiner = clean_examiner_name(line)\n",
    "        active_question = ''\n",
    "\n",
    "    # when we hit an answer, I want the active_question to be everything since the last question\n",
    "    elif starts_question(line, current_examiner):\n",
    "        active_question = line # start adding to active_question\n",
    "\n",
    "    elif is_answer(line):\n",
    "        if current_examiner == '': # error in pdf reading: no examiner info \n",
    "            current_examiner = guess_examiner(current_witness_side, current_examination)\n",
    "\n",
    "        if '?' in active_question: # to rule out things like \"Q. Good morning.\"\n",
    "            if current_examiner not in name_to_stats[current_witness].keys():\n",
    "                name_to_stats[current_witness][current_examiner] = {'total_questions': 0, 'yes_no_questions': 0}\n",
    "            name_to_stats[current_witness][current_examiner]['total_questions'] += 1\n",
    "            if is_yes_no(active_question):\n",
    "                name_to_stats[current_witness][current_examiner]['yes_no_questions'] += 1\n",
    "\n",
    "        active_question = '' # reset\n",
    "\n",
    "    elif active_question:\n",
    "        active_question += line # if we started a question, add this line. resets at every answer or special identifying line\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def get_unique_id(lines):\n",
    "    for l in lines[0:30]:\n",
    "        if 'NO. ' in l: # case number\n",
    "            return 'case-' + l.split('NO. ')[1].strip()\n",
    "    return datetime.now().strftime('date-%Y-%m-%d_%H-%M')\n",
    "\n",
    "\n",
    "output_text = 'Witness Yes/No Question Statistics \\n\\n'\n",
    "\n",
    "for name,values in name_to_stats.items():\n",
    "    output_text += f'Witness: {name}\\n'\n",
    "    for examiner, stats in values.items():\n",
    "        output_text += f'\\tExaminer: {examiner}\\n'\n",
    "        output_text += f'\\t\\t Yes/no questions: {stats[\"yes_no_questions\"]}\\n'\n",
    "        output_text += f'\\t\\t Total questions: {stats[\"total_questions\"]}\\n'\n",
    "\n",
    "        try:\n",
    "            percentage = round(stats['yes_no_questions'] / stats['total_questions'] * 100, 2)\n",
    "        except:\n",
    "             percentage = 'error: no questions'\n",
    "        output_text += f'\\t\\t Yes/no percentage: {percentage}%\\n'\n",
    "    output_text += '\\n'\n",
    "\n",
    "with open(f'yn_transcript_output_{get_unique_id(lines)}.txt', 'w') as file: # CHANGE FILENAME TO UNIQUE ID\n",
    "    file.write(output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506 1244\n"
     ]
    }
   ],
   "source": [
    "# THERE ARE MANY PROBLEMS\n",
    "# lines that are either questions or answers, that don't start with Q. or A. when the pdf is read by this software :(\n",
    "# this gets all the indices of those -- fix later\n",
    "\n",
    "current = ''\n",
    "i1 = []\n",
    "i2 = []\n",
    "for i,line in enumerate(lines):\n",
    "    if 'THE COURT' in line or 'OBJECTION' in line.upper():\n",
    "        current = ''\n",
    "    if 'Q. ' in line[0:10]:\n",
    "        if current=='question':\n",
    "            i1.append(i)\n",
    "        current = 'question'\n",
    "    if 'A. ' in line[0:10]:\n",
    "        if current=='answer':\n",
    "            i2.append(i)\n",
    "        current = 'answer'\n",
    "print(len(i1), len(i2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
