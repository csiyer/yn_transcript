{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial transcript yes/no analysis\n",
    "\n",
    "This code will read trial transcript PDFs and for each witness (and each questioner) quantify how many yes/no questions that witness is asked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input:\n",
    "- file path of folder containing transcript PDFs (currently, this should be run separately for each case/trial)\n",
    "\n",
    "Output:\n",
    "- writes a text file containing witness statistics, for each examiner, of # of yes/no questions and # total questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: there are some instances where the PDF reader just misses some lines, so this won't be 100% accurate. This code contains a couple shortcuts for guessing information that was lost in the PDF reading process.\n",
    "\n",
    "For example, look at `12RT.pdf` page 95 // loc 1721. Compare to `entire_transcript[1984825: 1984890]` or `lines[77314:77316]`--these are missing two lines between \"DIRECT EXAMINATION\" and \"A. POLICE OFFICER WITH THE...\"\n",
    "\n",
    "In this example, the examiner is not identified, and the question asked is not identified. This is rare. But in these rare cases, we will guess who the examiner is, and try to infer whether it was a yes/no question from the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIRECTORY_PATH = \"example_transcripts\"\n",
    "THOROUGH_BOOL = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pypdf\n",
    "# %pip install tqdm\n",
    "# %pip install transformers\n",
    "# %pip install torch\n",
    "# %pip install openai\n",
    "# %pip install joblib\n",
    "\n",
    "import os, re, argparse\n",
    "from datetime import datetime\n",
    "from pypdf import PdfReader\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "from joblib import Parallel, delayed\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDFs to text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33/33 [00:42<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Read all the PDFs into a huge string, and then split into a big list of lines\n",
    "files = [f for f in sorted(os.listdir(INPUT_DIRECTORY_PATH))]\n",
    "entire_transcript = \"\"\n",
    "print('Processing PDFs to text...')\n",
    "for file in tqdm(files, total=len(files)):\n",
    "  reader = PdfReader(os.path.join(INPUT_DIRECTORY_PATH, file))\n",
    "  for page in reader.pages:\n",
    "    entire_transcript += page.extract_text() + '\\n'\n",
    "print('finished!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate into lines, and filter out the ones that are just line numbers, e.g. \"24 \"\n",
    "lines = entire_transcript.split('\\n')\n",
    "lines = [line for line in lines if not re.match(r'^[\\d\\s]*$', line)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process transcript into witness statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "def delete_numbers_whitespace(text):\n",
    "    return re.sub(r'[\\d\\t\\n]', '', text).strip()\n",
    "\n",
    "def clean_simple_line(line):\n",
    "    # removes punctuation/numbers/non-letters\n",
    "    return re.sub(r'[^a-zA-Z\\s]', '', line).upper().strip() \n",
    "\n",
    "def line_is_witness_identifier(lines, i):\n",
    "    line = clean_simple_line(lines[i])\n",
    "    words = line.split(' ')\n",
    "    return len(words) < 6 and i < len(lines)-1 and ' as a witness' in lines[i+1].lower()\n",
    "\n",
    "def who_presents_this_witness(lines, witness_line_i): \n",
    "    for j in range(witness_line_i+1, witness_line_i+5): # scan the next few lines for keywords\n",
    "        if 'people' in lines[j].lower():\n",
    "            return 'people'\n",
    "        if 'defense' in lines[j].lower() or 'defendant' in lines[j].lower():\n",
    "            return 'defense'\n",
    "    return 'unknown'\n",
    "\n",
    "def line_is_examiner_identifier(line):\n",
    "    # each examination begins with a line like \"By Mr. Smith:\"  \n",
    "    line = re.sub(r'\\d+', '', line).strip() # eliminate leading numbers + whitespace. we don't want clean_simple_line because we want to keep colon if there is one\n",
    "    return len(line.split(' ')) < 6 and line[0:2].lower() == 'by' and line.strip()[-1] == ':'\n",
    "\n",
    "def clean_examiner_name(examiner_line):\n",
    "    if '.' in examiner_line and ':' in examiner_line:\n",
    "        name_substr = examiner_line[examiner_line.find('.'):examiner_line.find(':')]\n",
    "        return clean_simple_line(name_substr)\n",
    "    \n",
    "    name_followed_by_colon = [w for w in examiner_line.split(' ') if ':' in w][0]\n",
    "    return clean_simple_line(name_followed_by_colon)\n",
    "\n",
    "def line_is_examination_identifier(lines, i):\n",
    "    line = clean_simple_line(lines[i])\n",
    "    return len(line.split()) < 4 and 'EXAMINATION' in line and ('CROSS' in line or 'DIRECT' in line) and i < len(lines)-1 and ( \n",
    "        line_is_examiner_identifier(lines[i+1]) or lines[i+1].startswith('Q.') or lines[i+1].startswith('A.')\n",
    "        )\n",
    "\n",
    "def is_answer(line):\n",
    "    return  re.sub(r'[^a-zA-Z. ]', '', line).strip().startswith('A. ') # or line.strip().startswith('THE WITNESS:')\n",
    "\n",
    "def starts_question(text, current_examiner):\n",
    "    return any(item in text for item in ['Q. ', 'Q . ', 'Q• ', 'Q • ', current_examiner+':']) # and '?' in text\n",
    "\n",
    "def guess_previous_question(lines, i):\n",
    "    # if the previous question was not read in properly with 'Q.', then we want to parse what the question was when we hit an answer\n",
    "    possible_question = lines[i-1]\n",
    "    for prevline in reversed(lines[i-11:i-2]): # check previous 10 lines for question, stop when we hit punctuation\n",
    "        if prevline.strip().endswith(('.','!','?')) or any(item in prevline for item in ['A. ', 'A . ']):\n",
    "            break\n",
    "        possible_question = prevline + possible_question\n",
    "    return delete_numbers_whitespace(possible_question) \n",
    "\n",
    "def is_yes_no_answer(lines,i,current_examiner):\n",
    "    # querying chatGPT for yes/no questions is very time consuming, so we only want to do it if we cannot tell from the answer itself\n",
    "    answer = lines[i]\n",
    "    for nextline in lines[i+1:i+10]: # check next lines and add continuance of answer if necessary\n",
    "        if nextline.strip().endswith(('.','!','?')) or is_answer(nextline) or starts_question(nextline, current_examiner):\n",
    "            break\n",
    "        answer += nextline\n",
    "\n",
    "    answer_split = re.sub(r'[^A-Za-z ]', '', answer).upper().strip().split(' ')\n",
    "    if any(item in answer_split for item in ['YES', 'YEAH', 'YEP', 'NO', 'NOPE', 'UHHUH', 'UHUH', 'UMHUM', 'UMUM']) or 'NOT' in answer_split[0:3]:\n",
    "        if len(answer_split) < 8:\n",
    "            return 'yes'\n",
    "        return 'maybe'\n",
    "    if len(answer_split) < 5:\n",
    "        return 'maybe'\n",
    "    return 'no'\n",
    "\n",
    "def is_yes_no(question):\n",
    "    # returns true if the question is a yes/no question. queries GPT to do so!\n",
    "    with open('key.txt', 'r') as f:\n",
    "        KEY = f.read()\n",
    "    client = OpenAI(api_key=KEY)\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert at identifying yes/no questions, and at analyzing courtroom transcripts.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Is the following question a yes or no question? Respond with 'yes' or 'no':\\n\\nQuestion: {question}\"}\n",
    "        ]\n",
    "    )\n",
    "    return 'yes' == completion.choices[0].message.content.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default examiner default guesses:  {'people': 'ARNOLD', 'defense': 'JAFFE'} \n",
      "If these look incorrect, please stop and revise.\n"
     ]
    }
   ],
   "source": [
    "# IDENTIFY DEFAULT EXAMINERS\n",
    "# there are some instances where the 'examiner identification' line isn't read properly by the pdf reader\n",
    "# for these, we'll find the first direct examination for each side (people/defense) and save who the examiner is -- this is a good guess\n",
    "\n",
    "DEFAULT_EXAMINER_KEY = {'people': '', 'defense': ''}\n",
    "found = {'people': False, 'defense': False}\n",
    "for i in range(len(lines)):\n",
    "    if line_is_witness_identifier(lines, i):\n",
    "        side = who_presents_this_witness(lines, i)\n",
    "        if side != 'unknown' and not found[side]:\n",
    "            # search the next 200 lines for a direct exam, if found one then get the examiner ID\n",
    "            direct_exam_found = True\n",
    "            for j,line in enumerate(lines[i:i+200]):\n",
    "                if line_is_examination_identifier(lines, i+j) and 'DIRECT' in line:\n",
    "                    direct_exam_found = True\n",
    "                if direct_exam_found and line_is_examiner_identifier(line):\n",
    "                    DEFAULT_EXAMINER_KEY[side] = clean_examiner_name(line)\n",
    "                    found[side] = True\n",
    "                    break\n",
    "    if found['people'] and found['defense']: \n",
    "        break\n",
    "    \n",
    "print('Default examiner default guesses: ', DEFAULT_EXAMINER_KEY, '\\nIf these look incorrect, please stop and revise.')\n",
    "\n",
    "def guess_examiner(witness_side, current_examination):\n",
    "    print('Examiner not found, guessing from previous records (this message should be rare).')\n",
    "    if 'DIRECT' in current_examination.upper():\n",
    "        return DEFAULT_EXAMINER_KEY[witness_side]\n",
    "    elif 'CROSS' in current_examination.upper():\n",
    "        other_side = [i for i in DEFAULT_EXAMINER_KEY.keys() if i != witness_side][0]\n",
    "        return DEFAULT_EXAMINER_KEY[other_side]\n",
    "    return 'error: unknown examiner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### LOOP THROUGH AND ANALYZE TRANSCRIPT\n",
    "\n",
    "# split this process into ranges of lines corresponding to each witness (to parallelize for speed)\n",
    "def process_one_range(range_of_lines, lines):\n",
    "    # initialize variables to be used as we loop\n",
    "    current_witness = ''\n",
    "    current_witness_side = ''\n",
    "    current_examination = ''\n",
    "    current_examiner = ''\n",
    "    active_question = ''\n",
    "    gpt_query_idxs = []\n",
    "    local_name_to_stats = defaultdict(lambda: defaultdict(lambda: {'total_questions': 0, 'yes_no_questions': 0})) # use default dict so we don't have to check if key already exists\n",
    "\n",
    "    for i in range_of_lines:\n",
    "        line = lines[i]\n",
    "\n",
    "        if line_is_witness_identifier(lines, i):\n",
    "            current_witness = clean_simple_line(line)\n",
    "            current_witness_side = who_presents_this_witness(lines, i)\n",
    "            active_question = '' # just in case we get carried away\n",
    "\n",
    "        elif line_is_examination_identifier(lines, i):\n",
    "            current_examiner = ''\n",
    "            current_examination = clean_simple_line(line)\n",
    "            active_question = ''\n",
    "\n",
    "        elif line_is_examiner_identifier(line):\n",
    "            current_examiner = clean_examiner_name(line)\n",
    "            active_question = ''\n",
    "\n",
    "        elif starts_question(line, current_examiner): # when we eventually hit an answer, I want the active_question to contain everything since the last question started\n",
    "            active_question = line # start adding to active_question\n",
    "\n",
    "        elif is_answer(line):\n",
    "            # we may need to guess necessary preceding info if there was an error in pdf reading\n",
    "            if current_examiner == '': \n",
    "                current_examiner = guess_examiner(current_witness_side, current_examination) \n",
    "            if active_question == '': \n",
    "                active_question = guess_previous_question(lines, i) \n",
    "                \n",
    "            if '?' in active_question: # to rule out things like \"Q. Good morning.\"\n",
    "                local_name_to_stats[current_witness][current_examiner]['total_questions'] += 1\n",
    "\n",
    "                yes_no = is_yes_no_answer(lines, i, current_examiner)\n",
    "\n",
    "                if yes_no == 'yes': \n",
    "                    local_name_to_stats[current_witness][current_examiner]['yes_no_questions'] += 1\n",
    "\n",
    "                # if we're being maximally thorough, or we're not but the yes_no function returned \"maybe\" -- query GPT \n",
    "                elif THOROUGH_BOOL or (not THOROUGH_BOOL and yes_no=='maybe'): \n",
    "                    gpt_query_idxs.append(i)\n",
    "                    local_name_to_stats[current_witness][current_examiner]['yes_no_questions'] += is_yes_no(active_question) # 1 if true, 0 if false\n",
    "\n",
    "            active_question = '' # reset\n",
    "\n",
    "        elif active_question:\n",
    "            active_question += line # if we started a question, add this line. resets at every answer or special identifying line\n",
    "\n",
    "    return dict(local_name_to_stats), gpt_query_idxs\n",
    "\n",
    "\n",
    "def merge_dicts(list_of_dicts):\n",
    "    main = defaultdict(lambda: defaultdict(lambda: {'total_questions': 0, 'yes_no_questions': 0}))\n",
    "    for d in list_of_dicts:\n",
    "        for witness, subdict in d.items():\n",
    "            for examiner, values in subdict.items():\n",
    "                main[witness][examiner]['total_questions'] += values['total_questions']\n",
    "                main[witness][examiner]['yes_no_questions'] += values['yes_no_questions']\n",
    "    return {k:dict(v) for k,v in main.items()}\n",
    "\n",
    "\n",
    "#### PROCESS ENTIRE TRANSCRIPT (in parallel)\n",
    "\n",
    "# find witness IDs to break the transcript into chunks, to hand each chunk to a separate cpu\n",
    "witness_breaks = [i for i in range(len(lines)) if line_is_witness_identifier(lines, i)] \n",
    "witness_ranges = [range(0, witness_breaks[i]) if i == 0 else range(witness_breaks[i-1], witness_breaks[i]) for i in range(len(witness_breaks))]\n",
    "\n",
    "results = Parallel(n_jobs=-1)(delayed(process_one_range)(r, lines) for r in witness_ranges)\n",
    "\n",
    "name_to_stats = merge_dicts([r[0] for r in results])\n",
    "all_gpt_query_idxs = [idx for sublist in [r[1] for r in results] for idx in sublist]\n",
    "\n",
    "print(f'Finished transcript, saving output.\\nTotal GPT queries: {len(all_gpt_query_idxs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_csv_text = 'Witness,Examiner,Total questions,Yes/No Questions,Yes/No Percentage\\n'\n",
    "for name,values in name_to_stats.items():\n",
    "    for examiner, stats in values.items():\n",
    "        output_csv_text += f'{name},{examiner},{stats[\"yes_no_questions\"]},{stats[\"total_questions\"]},'\n",
    "        try:\n",
    "            percentage = round(stats['yes_no_questions'] / stats['total_questions'] * 100, 2)\n",
    "        except:\n",
    "             percentage = 'N/A'\n",
    "        output_csv_text += f'{percentage}\\n'\n",
    "    output_csv_text += '\\n'\n",
    "\n",
    "def get_unique_id(lines):\n",
    "    for l in lines[0:30]:\n",
    "        if 'NO. ' in l: # case number\n",
    "            return 'case-' + l.split('NO. ')[1].strip()\n",
    "    return datetime.now().strftime('date-%Y-%m-%d_%H-%M')\n",
    "\n",
    "thorough_tag = 'thorough' if THOROUGH_BOOL  else 'nonthorough'\n",
    "output_path = os.path.join(INPUT_DIRECTORY_PATH, f'yesno_analysis_{get_unique_id(lines)}_{thorough_tag}.csv')\n",
    "\n",
    "with open(output_path, 'w') as file: # CHANGE FILENAME TO UNIQUE ID\n",
    "    file.write(output_csv_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "506 1244\n"
     ]
    }
   ],
   "source": [
    "# THERE ARE MANY PROBLEMS\n",
    "# lines that are either questions or answers, that don't start with Q. or A. when the pdf is read by this software :(\n",
    "# this gets all the indices of those -- fix later\n",
    "\n",
    "current = ''\n",
    "i1 = []\n",
    "i2 = []\n",
    "for i,line in enumerate(lines):\n",
    "    if 'THE COURT' in line or 'OBJECTION' in line.upper():\n",
    "        current = ''\n",
    "    if 'Q. ' in line[0:10]:\n",
    "        if current=='question':\n",
    "            i1.append(i)\n",
    "        current = 'question'\n",
    "    if 'A. ' in line[0:10]:\n",
    "        if current=='answer':\n",
    "            i2.append(i)\n",
    "        current = 'answer'\n",
    "print(len(i1), len(i2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WITNESS_TO_DEBUG = 'IRIS THOMAS'\n",
    "\n",
    "current_witness = ''\n",
    "current_witness_side = ''\n",
    "current_examination = ''\n",
    "current_examiner = ''\n",
    "active_question = ''\n",
    "\n",
    "line_output = ''\n",
    "\n",
    "for i,line in enumerate(lines):\n",
    "\n",
    "    line_output = ''\n",
    "\n",
    "    if line_is_witness_identifier(lines, i):\n",
    "        current_witness = clean_simple_line(line)\n",
    "        current_witness_side = who_presents_this_witness(lines, i)\n",
    "        if current_witness not in name_to_stats.keys():\n",
    "            name_to_stats[current_witness] = {}\n",
    "        active_question = '' # just in case we get carried away\n",
    "\n",
    "        line_output += 'witness // '\n",
    "\n",
    "    elif line_is_examination_identifier(lines, i):\n",
    "        current_examiner = ''\n",
    "        current_examination = clean_simple_line(line)\n",
    "        active_question = ''\n",
    "\n",
    "        line_output += 'exam // '\n",
    "\n",
    "    elif line_is_examiner_identifier(line):\n",
    "        current_examiner = clean_examiner_name(line)\n",
    "        active_question = ''\n",
    "\n",
    "        line_output += 'examiner // '\n",
    "\n",
    "    if current_witness == WITNESS_TO_DEBUG:\n",
    "\n",
    "        # when we hit an answer, I want the active_question to be everything since the last question\n",
    "        if starts_question(line, current_examiner):\n",
    "            active_question = line # start adding to active_question\n",
    "\n",
    "            line_output += 'startsQ // '\n",
    "\n",
    "        elif is_answer(line):\n",
    "\n",
    "            line_output += 'answer // '\n",
    "\n",
    "            if current_examiner == '': # error in pdf reading: no examiner info \n",
    "                current_examiner = guess_examiner(current_witness_side, current_examination)\n",
    "            if active_question == '':\n",
    "                active_question = guess_previous_question(lines, i)\n",
    "\n",
    "            if '?' in active_question: # to rule out things like \"Q. Good morning.\"\n",
    "\n",
    "                line_output += '?before // '\n",
    "\n",
    "                yes_no = is_yes_no_answer(lines, i, current_examiner)\n",
    "                if yes_no == 'yes':\n",
    "                    line_output += 'yesno // '\n",
    "\n",
    "                elif yes_no == 'maybe':\n",
    "                    if is_yes_no(active_question): # query gpt only if we have to\n",
    "                        line_output += 'maybe-yes // '\n",
    "                    else:\n",
    "                        line_output += 'maybe-no // '\n",
    "\n",
    "                else:\n",
    "                    line_output += 'not-yesno // '\n",
    "\n",
    "            active_question = '' # reset\n",
    "\n",
    "        elif active_question:\n",
    "            active_question += line # if we started a question, add this line. resets at every answer or special identifying line\n",
    "\n",
    "        print(i, line_output, line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
